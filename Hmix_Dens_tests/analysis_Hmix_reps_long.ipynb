{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the subdirectories you want to loop through\n",
    "subdirs = ['1000l_r1', '1000l_r2', '1000l_r3', '1000l_r4','1000l_r5','1000l_r6']  # List of subdirectories you want to loop through\n",
    "file_posfix='1000_20ns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_name):\n",
    "    # Specify the subdirectories you want to loop through\n",
    "    dict_name = {}  # Dictionary to store dict_name\n",
    "\n",
    "    # Loop through each subdirectory\n",
    "    for subdir in subdirs:\n",
    "        length=(len(subdir))\n",
    "        n_rep=3\n",
    "        newname=subdir[length-n_rep:]\n",
    "        # Construct the path to the CSV file (assuming the CSV has the same name as the subdir)\n",
    "        file_path = os.path.join(os.getcwd(), subdir, f'{file_name}')\n",
    "\n",
    "        # Read the CSV into a pandas dataframe\n",
    "        if os.path.exists(file_path):\n",
    "            if '.csv' in file_name:\n",
    "                df = pd.read_csv(file_path)\n",
    "                dict_name[f'df_stats{newname}'] = df\n",
    "            elif '.json' in file_name:    \n",
    "                df = pd.read_json(file_path)\n",
    "            # Store the dataframe with a unique name (using the subdirectory name)\n",
    "                if 'excess' in file_name:\n",
    "                    dict_name[f'value{newname}'] = df['.result']['value']['value']\n",
    "                    dict_name[f'error{newname}'] = df['.result']['value']['error']\n",
    "                elif 'build' in file_name:\n",
    "                    dict_name[f'molecule_number{newname}'] = df['.output_number_of_molecules'][0]\n",
    "                    dict_name[f'molefraction_0{newname}'] = df['.output_substance']['amounts']['O{solv}'][0]['value']\n",
    "                    dict_name[f'molefraction_1{newname}'] = df['.output_substance']['amounts']['OCCN(CCO)CCO{solv}'][0]['value']\n",
    "                else:\n",
    "                    dict_name[f'value{newname}'] = df['.value']['value']['value']\n",
    "                    dict_name[f'error{newname}'] = df['.value']['value']['error']\n",
    "                    dict_name[f'n_total_points{newname}'] = df['.time_series_statistics'][\"n_total_points\"]\n",
    "                    dict_name[f'n_uncorrelated_points{newname}'] = df['.time_series_statistics'][\"n_uncorrelated_points\"]\n",
    "                    dict_name[f'statistical_inefficiency{newname}'] = df['.time_series_statistics'][\"statistical_inefficiency\"]\n",
    "                    dict_name[f'equilibration_index{newname}'] = df['.time_series_statistics'][\"equilibration_index\"]\n",
    "\n",
    "            print(f\"Data from {subdir} loaded successfully into dataframe: {subdir}\")\n",
    "        else:\n",
    "            print(f\"Data not found in {subdir}\")\n",
    "    return dict_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 1000l_r1 loaded successfully into dataframe: 1000l_r1\n",
      "Data from 1000l_r2 loaded successfully into dataframe: 1000l_r2\n",
      "Data from 1000l_r3 loaded successfully into dataframe: 1000l_r3\n",
      "Data from 1000l_r4 loaded successfully into dataframe: 1000l_r4\n",
      "Data from 1000l_r5 loaded successfully into dataframe: 1000l_r5\n",
      "Data from 1000l_r6 loaded successfully into dataframe: 1000l_r6\n"
     ]
    }
   ],
   "source": [
    "system=extract_data('6421_build_coordinates_mixture_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def are_values_of_keys_equal(dictionary, keys):\n",
    "    # Extract the values of the specified keys from the dictionary\n",
    "    values = [dictionary.get(key) for key in keys]\n",
    "    \n",
    "    # Check if all values are the same\n",
    "    return all(value == values[0] for value in values)\n",
    "        \n",
    "\n",
    "keys_to_check_molnumber = []\n",
    "keys_to_check_mf0 = []\n",
    "keys_to_check_mf1 = []\n",
    "\n",
    "for key,val in system.items():\n",
    "    for rep in range(1,7):\n",
    "        if 'molecule_number' in key:\n",
    "            keys_to_check_molnumber.append(f'{key[:-1]}{rep}')\n",
    "\n",
    "        if 'molefraction_0' in key:\n",
    "            keys_to_check_mf0.append(f'{key[:-1]}{rep}')\n",
    "\n",
    "        if 'molefraction_1' in key:\n",
    "            keys_to_check_mf1.append(f'{key[:-1]}{rep}')\n",
    "            \n",
    "print(are_values_of_keys_equal(system, keys_to_check_molnumber))\n",
    "print(are_values_of_keys_equal(system, keys_to_check_mf0))\n",
    "print(are_values_of_keys_equal(system, keys_to_check_mf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0.51\n",
      "0.49\n"
     ]
    }
   ],
   "source": [
    "print(system['molecule_number_r1'])\n",
    "print(system['molefraction_0_r1'])\n",
    "print(system['molefraction_1_r1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thermoml_MF_c1=0.4902\n",
    "thermoml_MF_c0=0.5098\n",
    "evaluator_MF_c1=system['molefraction_1_r1']\n",
    "evaluator_MF_c0=system['molefraction_0_r1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENERGY STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 1000l_r1 loaded successfully into dataframe: 1000l_r1\n",
      "Data from 1000l_r2 loaded successfully into dataframe: 1000l_r2\n",
      "Data from 1000l_r3 loaded successfully into dataframe: 1000l_r3\n",
      "Data from 1000l_r4 loaded successfully into dataframe: 1000l_r4\n",
      "Data from 1000l_r5 loaded successfully into dataframe: 1000l_r5\n",
      "Data from 1000l_r6 loaded successfully into dataframe: 1000l_r6\n"
     ]
    }
   ],
   "source": [
    "stats=extract_data('openmm_statistics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_stats={}\n",
    "means_stats['rep1'] = stats['df_stats_r1'].mean()\n",
    "means_stats['rep2'] = stats['df_stats_r2'].mean()\n",
    "means_stats['rep3'] = stats['df_stats_r3'].mean()\n",
    "means_stats['rep4'] = stats['df_stats_r4'].mean()\n",
    "means_stats['rep5'] = stats['df_stats_r5'].mean()\n",
    "means_stats['rep6'] = stats['df_stats_r6'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: rep1\n",
      "Key: rep2\n",
      "Key: rep3\n",
      "Key: rep4\n",
      "Key: rep5\n",
      "Key: rep6\n"
     ]
    }
   ],
   "source": [
    "PE=[]\n",
    "KE=[]\n",
    "TE=[]\n",
    "bVol=[]\n",
    "dens=[]\n",
    "\n",
    "for key, value_list in means_stats.items():\n",
    "    print(f'Key: {key}')\n",
    "    # print(f'Values: {value_list}')\n",
    "    PE.append(value_list.iloc[1])\n",
    "    KE.append(value_list.iloc[2])\n",
    "    TE.append(value_list.iloc[3])\n",
    "    bVol.append(value_list.iloc[5])\n",
    "    dens.append(value_list.iloc[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hmix replicates, Potential Energy (kJ/mol): 59951.433 +/- 59.593\n",
      "Hmix replicates, Kinetic Energy (kJ/mol): 39317.899 +/- 2.373\n",
      "Hmix replicates, Total Energy (kJ/mol): 99269.332 +/- 59.942\n",
      "Hmix replicates, Box Volume (nm^3): 120.481 +/- 0.063\n",
      "Hmix replicates, Density (g/mL): 1.134 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "## Calculate means and MSE\n",
    "PE_mean=np.array(PE).mean()\n",
    "PE_std=np.array(PE).std(ddof=1)\n",
    "PE_err=PE_std/np.sqrt(len(PE))\n",
    "print(f'Hmix replicates, Potential Energy (kJ/mol): {PE_mean:.3f} +/- {PE_err:.3f}')\n",
    "\n",
    "KE_mean=np.array(KE).mean()\n",
    "KE_std=np.array(KE).std(ddof=1)\n",
    "KE_err=KE_std/np.sqrt(len(KE))\n",
    "print(f'Hmix replicates, Kinetic Energy (kJ/mol): {KE_mean:.3f} +/- {KE_err:.3f}')\n",
    "\n",
    "TE_mean=np.array(TE).mean()\n",
    "TE_std=np.array(TE).std(ddof=1)\n",
    "TE_err=TE_std/np.sqrt(len(TE))\n",
    "print(f'Hmix replicates, Total Energy (kJ/mol): {TE_mean:.3f} +/- {TE_err:.3f}')\n",
    "\n",
    "bVol_mean=np.array(bVol).mean()\n",
    "bVol_std=np.array(bVol).std(ddof=1)\n",
    "bVol_err=bVol_std/np.sqrt(len(bVol))\n",
    "print(f'Hmix replicates, Box Volume (nm^3): {bVol_mean:.3f} +/- {bVol_err:.3f}')\n",
    "\n",
    "dens_mean=np.array(dens).mean()\n",
    "dens_std=np.array(dens).std(ddof=1)\n",
    "dens_err=dens_std/np.sqrt(len(dens))\n",
    "print(f'Hmix replicates, Density (g/mL): {dens_mean:.3f} +/- {dens_err:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "molnumb=system['molecule_number_r1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'output_stats_{file_posfix}.txt', 'w') as file:\n",
    "    file.write(f'Molecule number: {molnumb} \\n')\n",
    "    file.write(f'Hmix {file_posfix} replicates, Average Potential Energy (kJ/mol): {PE_mean:.3f} +/- {PE_err:.3f} \\n')\n",
    "    file.write(f'Hmix {file_posfix} replicates, Average Kinetic Energy (kJ/mol): {KE_mean:.3f} +/- {KE_err:.3f} \\n')\n",
    "    file.write(f'Hmix {file_posfix} replicates, Average Total Energy (kJ/mol): {TE_mean:.3f} +/- {TE_err:.3f} \\n')\n",
    "    file.write(f'Hmix {file_posfix} replicates, Average Box Volume (nm^3): {bVol_mean:.3f} +/- {bVol_err:.3f} \\n')\n",
    "    file.write(f'Hmix {file_posfix} replicates, Average Density (g/mL): {dens_mean:.3f} +/- {dens_err:.3f} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 1000l_r1 loaded successfully into dataframe: 1000l_r1\n",
      "Data from 1000l_r2 loaded successfully into dataframe: 1000l_r2\n",
      "Data from 1000l_r3 loaded successfully into dataframe: 1000l_r3\n",
      "Data from 1000l_r4 loaded successfully into dataframe: 1000l_r4\n",
      "Data from 1000l_r5 loaded successfully into dataframe: 1000l_r5\n",
      "Data from 1000l_r6 loaded successfully into dataframe: 1000l_r6\n"
     ]
    }
   ],
   "source": [
    "final_results=extract_data('6421_calculate_excess_observable_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_r1:-1.00438788652093\n",
      "error_r1:0.027793276305126003\n",
      "value_r2:-1.359631594605289\n",
      "error_r2:0.029301131494792004\n",
      "value_r3:-1.394975354843708\n",
      "error_r3:0.030597590011105003\n",
      "value_r4:-1.279081061707629\n",
      "error_r4:0.037290156173098006\n",
      "value_r5:-0.975410929143194\n",
      "error_r5:0.036557577563663006\n",
      "value_r6:-1.511265698933385\n",
      "error_r6:0.038797612410837005\n"
     ]
    }
   ],
   "source": [
    "obs_values=[]\n",
    "obs_errors=[]\n",
    "for key, mr in final_results.items():\n",
    "    if 'value' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        obs_values.append(mr['value'])\n",
    "    elif 'error' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        obs_errors.append(mr['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'output_observables_{file_posfix}.txt', 'w') as file:\n",
    "    file.write(f'Values list: {obs_values} \\n')\n",
    "    file.write(f'Errors list: {obs_errors} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIXTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 1000l_r1 loaded successfully into dataframe: 1000l_r1\n",
      "Data from 1000l_r2 loaded successfully into dataframe: 1000l_r2\n",
      "Data from 1000l_r3 loaded successfully into dataframe: 1000l_r3\n",
      "Data from 1000l_r4 loaded successfully into dataframe: 1000l_r4\n",
      "Data from 1000l_r5 loaded successfully into dataframe: 1000l_r5\n",
      "Data from 1000l_r6 loaded successfully into dataframe: 1000l_r6\n"
     ]
    }
   ],
   "source": [
    "mixout=extract_data('6421_extract_observable_mixture_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_r1:99.41846722926692\n",
      "error_r1:0.019630000121839002\n",
      "n_total_points_r1:5000\n",
      "n_uncorrelated_points_r1:960\n",
      "statistical_inefficiency_r1:1.919515007030599\n",
      "equilibration_index_r1:3081\n",
      "value_r2:99.03433328033205\n",
      "error_r2:0.026266070430326003\n",
      "n_total_points_r2:5000\n",
      "n_uncorrelated_points_r2:450\n",
      "statistical_inefficiency_r2:2.028505800425906\n",
      "equilibration_index_r2:3651\n",
      "value_r3:99.10532005743546\n",
      "error_r3:0.029030830654064\n",
      "n_total_points_r3:5000\n",
      "n_uncorrelated_points_r3:275\n",
      "statistical_inefficiency_r3:1.092257748264158\n",
      "equilibration_index_r3:4450\n",
      "value_r4:99.27380702714406\n",
      "error_r4:0.028834582186391\n",
      "n_total_points_r4:5000\n",
      "n_uncorrelated_points_r4:281\n",
      "statistical_inefficiency_r4:1.399651882184411\n",
      "equilibration_index_r4:4438\n",
      "value_r5:99.56847109367975\n",
      "error_r5:0.031823695662625\n",
      "n_total_points_r5:5000\n",
      "n_uncorrelated_points_r5:203\n",
      "statistical_inefficiency_r5:1.008136724567934\n",
      "equilibration_index_r5:4595\n",
      "value_r6:98.85450603530933\n",
      "error_r6:0.036566791633431\n",
      "n_total_points_r6:5000\n",
      "n_uncorrelated_points_r6:166\n",
      "statistical_inefficiency_r6:1.86443346017149\n",
      "equilibration_index_r6:4668\n"
     ]
    }
   ],
   "source": [
    "mixout_values=[]\n",
    "mixout_errors=[]\n",
    "mixout_totpts=[]\n",
    "mixout_uncorrpts=[]\n",
    "mixout_statineff=[]\n",
    "mixout_equilindex=[]\n",
    "\n",
    "for key, mr in mixout.items():\n",
    "    if 'value' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        mixout_values.append(mr['value'])\n",
    "    elif 'error' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        mixout_errors.append(mr['value'])\n",
    "    elif 'n_total_points' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        mixout_totpts.append(mr)\n",
    "    elif 'n_uncorrelated_points' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        mixout_uncorrpts.append(mr)\n",
    "    elif 'statistical_inefficiency' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        mixout_statineff.append(mr)\n",
    "    elif 'equilibration_index' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        mixout_equilindex.append(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'mixture_output_{file_posfix}.txt', 'w') as file:\n",
    "    file.write(f'Mixture Values list: {mixout_values} \\n')\n",
    "    file.write(f'Mixture Errors list: {mixout_errors} \\n')\n",
    "    file.write(f'Mixture Total points list: {mixout_totpts} \\n')\n",
    "    file.write(f'Mixture Uncorrelated points list: {mixout_uncorrpts} \\n')\n",
    "    file.write(f'Mixture Statistical inefficiency list: {mixout_statineff} \\n')\n",
    "    file.write(f'Mixture Equilibration index list: {mixout_equilindex} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPONENT 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 1000l_r1 loaded successfully into dataframe: 1000l_r1\n",
      "Data from 1000l_r2 loaded successfully into dataframe: 1000l_r2\n",
      "Data from 1000l_r3 loaded successfully into dataframe: 1000l_r3\n",
      "Data from 1000l_r4 loaded successfully into dataframe: 1000l_r4\n",
      "Data from 1000l_r5 loaded successfully into dataframe: 1000l_r5\n",
      "Data from 1000l_r6 loaded successfully into dataframe: 1000l_r6\n"
     ]
    }
   ],
   "source": [
    "comp0=extract_data('6422_extract_observable_component_0_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_r1:-44.87094396463476\n",
      "error_r1:0.005241095523625\n",
      "n_total_points_r1:5000\n",
      "n_uncorrelated_points_r1:2500\n",
      "statistical_inefficiency_r1:1.563413544543261\n",
      "equilibration_index_r1:0\n",
      "value_r2:-44.87249062157608\n",
      "error_r2:0.005503189687938\n",
      "n_total_points_r2:5000\n",
      "n_uncorrelated_points_r2:2500\n",
      "statistical_inefficiency_r2:1.421293642724092\n",
      "equilibration_index_r2:0\n",
      "value_r3:-44.87572711227428\n",
      "error_r3:0.005703782443673\n",
      "n_total_points_r3:5000\n",
      "n_uncorrelated_points_r3:2496\n",
      "statistical_inefficiency_r3:1.488460556606125\n",
      "equilibration_index_r3:9\n",
      "value_r4:-44.88168396954277\n",
      "error_r4:0.00570196725159\n",
      "n_total_points_r4:5000\n",
      "n_uncorrelated_points_r4:2500\n",
      "statistical_inefficiency_r4:1.426474810561663\n",
      "equilibration_index_r4:0\n",
      "value_r5:-44.88708656250604\n",
      "error_r5:0.0057649258555510004\n",
      "n_total_points_r5:5000\n",
      "n_uncorrelated_points_r5:2499\n",
      "statistical_inefficiency_r5:1.457967519409496\n",
      "equilibration_index_r5:2\n",
      "value_r6:-44.87892946171502\n",
      "error_r6:0.005199250522814\n",
      "n_total_points_r6:5000\n",
      "n_uncorrelated_points_r6:2500\n",
      "statistical_inefficiency_r6:1.462402994730489\n",
      "equilibration_index_r6:0\n"
     ]
    }
   ],
   "source": [
    "comp0_values=[]\n",
    "comp0_errors=[]\n",
    "comp0_totpts=[]\n",
    "comp0_uncorrpts=[]\n",
    "comp0_statineff=[]\n",
    "comp0_equilindex=[]\n",
    "\n",
    "for key, mr in comp0.items():\n",
    "    if 'value' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        comp0_values.append(mr['value'])\n",
    "    elif 'error' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        comp0_errors.append(mr['value'])\n",
    "    elif 'n_total_points' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp0_totpts.append(mr)\n",
    "    elif 'n_uncorrelated_points' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp0_uncorrpts.append(mr)\n",
    "    elif 'statistical_inefficiency' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp0_statineff.append(mr)\n",
    "    elif 'equilibration_index' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp0_equilindex.append(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Component0_output_{file_posfix}.txt', 'w') as file:\n",
    "    file.write(f'Component0 Values list: {comp0_values} \\n')\n",
    "    file.write(f'Component0 Errors list: {comp0_errors} \\n')\n",
    "    file.write(f'Component0 Total points list: {comp0_totpts} \\n')\n",
    "    file.write(f'Component0 Uncorrelated points list: {comp0_uncorrpts} \\n')\n",
    "    file.write(f'Component0 Statistical inefficiency list: {comp0_statineff} \\n')\n",
    "    file.write(f'Component0 Equilibration index list: {comp0_equilindex} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPONENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 1000l_r1 loaded successfully into dataframe: 1000l_r1\n",
      "Data from 1000l_r2 loaded successfully into dataframe: 1000l_r2\n",
      "Data from 1000l_r3 loaded successfully into dataframe: 1000l_r3\n",
      "Data from 1000l_r4 loaded successfully into dataframe: 1000l_r4\n",
      "Data from 1000l_r5 loaded successfully into dataframe: 1000l_r5\n",
      "Data from 1000l_r6 loaded successfully into dataframe: 1000l_r6\n"
     ]
    }
   ],
   "source": [
    "comp1=extract_data('6422_extract_observable_component_1_output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_r1:251.52603498359576\n",
      "error_r1:0.039766089868522\n",
      "n_total_points_r1:5000\n",
      "n_uncorrelated_points_r1:423\n",
      "statistical_inefficiency_r1:1.279845018945329\n",
      "equilibration_index_r1:4154\n",
      "value_r2:251.4687078617234\n",
      "error_r2:0.025866709452493003\n",
      "n_total_points_r2:5000\n",
      "n_uncorrelated_points_r2:941\n",
      "statistical_inefficiency_r2:1.656688179782199\n",
      "equilibration_index_r2:3119\n",
      "value_r3:251.68898632010732\n",
      "error_r3:0.018804196582712002\n",
      "n_total_points_r3:5000\n",
      "n_uncorrelated_points_r3:1173\n",
      "statistical_inefficiency_r3:1.918600363318369\n",
      "equilibration_index_r3:2654\n",
      "value_r4:251.80246955635369\n",
      "error_r4:0.047871109396957004\n",
      "n_total_points_r4:5000\n",
      "n_uncorrelated_points_r4:307\n",
      "statistical_inefficiency_r4:2.437083402835697\n",
      "equilibration_index_r4:4081\n",
      "value_r5:251.78971593714508\n",
      "error_r5:0.036210221205892006\n",
      "n_total_points_r5:5000\n",
      "n_uncorrelated_points_r5:361\n",
      "statistical_inefficiency_r5:3.255169164099932\n",
      "equilibration_index_r5:3557\n",
      "value_r6:251.4178906034782\n",
      "error_r6:0.025892441338233003\n",
      "n_total_points_r6:5000\n",
      "n_uncorrelated_points_r6:1081\n",
      "statistical_inefficiency_r6:1.4283528739815892\n",
      "equilibration_index_r6:2839\n"
     ]
    }
   ],
   "source": [
    "comp1_values=[]\n",
    "comp1_errors=[]\n",
    "comp1_totpts=[]\n",
    "comp1_uncorrpts=[]\n",
    "comp1_statineff=[]\n",
    "comp1_equilindex=[]\n",
    "\n",
    "for key, mr in comp1.items():\n",
    "    if 'value' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        comp1_values.append(mr['value'])\n",
    "    elif 'error' in key:\n",
    "        print(f\"{key}:{mr['value']}\")\n",
    "        comp1_errors.append(mr['value'])\n",
    "    elif 'n_total_points' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp1_totpts.append(mr)\n",
    "    elif 'n_uncorrelated_points' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp1_uncorrpts.append(mr)\n",
    "    elif 'statistical_inefficiency' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp1_statineff.append(mr)\n",
    "    elif 'equilibration_index' in key:\n",
    "        print(f\"{key}:{mr}\")\n",
    "        comp1_equilindex.append(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Component1_output_{file_posfix}.txt', 'w') as file:\n",
    "    file.write(f'Component1 Values list: {comp1_values} \\n')\n",
    "    file.write(f'Component1 Errors list: {comp1_errors} \\n')\n",
    "    file.write(f'Component1 Total points list: {comp1_totpts} \\n')\n",
    "    file.write(f'Component1 Uncorrelated points list: {comp1_uncorrpts} \\n')\n",
    "    file.write(f'Component1 Statistical inefficiency list: {comp1_statineff} \\n')\n",
    "    file.write(f'Component1 Equilibration index list: {comp1_equilindex} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimated_values(mole_fraction_source):\n",
    "    if mole_fraction_source == 'thermoML':\n",
    "        mf_c0=thermoml_MF_c0\n",
    "        mf_c1=thermoml_MF_c1\n",
    "    elif mole_fraction_source == 'evaluator':\n",
    "        mf_c0=evaluator_MF_c0\n",
    "        mf_c1=evaluator_MF_c1\n",
    "\n",
    "    for i in range(6):\n",
    "        estimated=mixout_values[i]-(mf_c1*comp1_values[i]+mf_c0*comp0_values[i])\n",
    "        est_error=np.sqrt((mf_c1*comp1_errors[i])**2 + (mf_c0*comp0_errors[i])**2 + mixout_errors[i]**2)\n",
    "        print(f'rep #{i+1}: {estimated} +/- {est_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep #1: -1.0043878865209308 +/- 0.027793276305125365\n",
      "rep #2: -1.3596315946052897 +/- 0.029301131494791976\n",
      "rep #3: -1.3949753548437087 +/- 0.03059759001110494\n",
      "rep #4: -1.279081061707629 +/- 0.037290156173097846\n",
      "rep #5: -0.9754109291431945 +/- 0.03655757756366293\n",
      "rep #6: -1.5112656989333857 +/- 0.03879761241083635\n"
     ]
    }
   ],
   "source": [
    "estimated_values('thermoML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep #1: -0.9451084907312719 +/- 0.027787799554846324\n",
      "rep #2: -1.3003633549086118 +/- 0.029298998550718536\n",
      "rep #3: -1.335662412157248 +/- 0.030596565667264243\n",
      "rep #4: -1.219744231002423 +/- 0.03728422085726234\n",
      "rep #5: -0.9160755686432509 +/- 0.036554154511555574\n",
      "rep #6: -1.452006334920327 +/- 0.03879598965645626\n"
     ]
    }
   ],
   "source": [
    "estimated_values('evaluator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
